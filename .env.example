# Smart Campus Environment Variables

# ============================================================================
# LOCAL MLX INTEGRATION (Phase 2)
# ============================================================================

# Enable local MLX server for classroom chat (instead of OpenAI cloud)
# Set to "true" to use local MLX, "false" to use OpenAI cloud API
ENABLE_LOCAL_AI=true

# URL of the local MLX OpenAI-compatible server
# Default: http://localhost:8000 (mlx-openai-server from Phase 1)
MLX_SERVER_URL=http://localhost:8000

# Model name to use when calling MLX server
# This should match a model loaded in the MLX server
# Example: mlx-community/qwen2.5-7b-instruct-4bit
MLX_MODEL_NAME=mlx-community/qwen2.5-7b-instruct-4bit

# Enable fallback to OpenAI cloud if MLX server is unreachable
# Requires OPENAI_API_KEY to be set
ENABLE_CLOUD_FALLBACK=false

# ============================================================================
# OPENAI CLOUD API (Fallback or Primary if ENABLE_LOCAL_AI=false)
# ============================================================================

# OpenAI API key for cloud fallback or primary chat
# Get from: https://platform.openai.com/api-keys
# Leave empty to use mock responses when MLX is disabled
OPENAI_API_KEY=

# ============================================================================
# LOGGING & OBSERVABILITY
# ============================================================================

# Log level for chat API (info, debug, error)
LOG_LEVEL=info

# Enable detailed request/response logging (for debugging)
# WARNING: May log sensitive data in development
DEBUG_CHAT_API=false
